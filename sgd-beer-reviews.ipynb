{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic gradient descent on beer reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I collaborated with Ruben Abbou."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "import time\n",
    "import random\n",
    "from math import exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/project2/cmsc25025/beer_review/labeled.json', 'r') as f:\n",
    "    brv = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data inspection.\n",
    "To warm up, check the mean, median and standard deviation of the overall ratings for each beer and brewer. Do you think people have similar taste?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "beers = set([br['beer_name'] for br in brv])\n",
    "brewers = set([br['brewer'] for br in brv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_values = {}\n",
    "for b in beers:\n",
    "    beer_values[b] = []\n",
    "for b in brv:\n",
    "    beer_values[b['beer_name']].append(b['overall'])\n",
    "beer_statistics = {}\n",
    "for k,v in beer_values.items():\n",
    "    beer_statistics[k] = {'sd': np.std(v), 'median': np.median(v), 'mean':np.mean(v)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "brewer_values = {}\n",
    "for b in brewers:\n",
    "    brewer_values[b] = []\n",
    "for b in brv:\n",
    "    brewer_values[b['brewer']].append(b['overall'])\n",
    "brewer_statistics = {}\n",
    "for k,v in brewer_values.items():\n",
    "    brewer_statistics[k] = {'sd': np.std(v), 'median': np.median(v), 'mean':np.mean(v)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beer: Schoune La Trip des Schoune\n",
      "mean: 12.17910447761194 median: 13.0 sd: 2.849065692019515\n",
      "Beer: Full Circle Euro-Fuggle\n",
      "mean: 12.285714285714286 median: 11.0 sd: 3.1036515689143473\n",
      "Beer: Blue Frog 10th Anniversary Ale\n",
      "mean: 15.166666666666666 median: 16.0 sd: 2.266911751455907\n",
      "Beer: Quay Street Blue Water Pale Ale\n",
      "mean: 12.0 median: 11.5 sd: 1.632993161855452\n",
      "Beer: Captain Lawrence Barrel Select Cherry\n",
      "mean: 14.0 median: 14.5 sd: 1.632993161855452\n",
      "Beer: Lost Abbey Gift of the Magi\n",
      "mean: 15.01126126126126 median: 15.0 sd: 1.7313638935078186\n",
      "Beer: John Harvards Brewers Gold\n",
      "mean: 10.0 median: 10.0 sd: 0.0\n",
      "Beer: Kelham Island Island\n",
      "mean: 13.4 median: 13.0 sd: 0.48989794855663565\n",
      "Beer: Hidden Fantasy\n",
      "mean: 12.0625 median: 12.0 sd: 2.0757152381769517\n",
      "Beer: Red Rock Czech Pilsner\n",
      "mean: 9.5 median: 9.0 sd: 2.362907813126304\n",
      "Beer: Bull Falls March Madness Ale\n",
      "mean: 15.0 median: 15.0 sd: 0.0\n",
      "Beer: Freisinger Schwarzbier\n",
      "mean: 12.307692307692308 median: 12.0 sd: 1.6817854699288806\n",
      "Beer: BryggeriKAIA Bayer\n",
      "mean: 14.0 median: 14.0 sd: 0.0\n",
      "Beer: Bayhawk Stout\n",
      "mean: 16.0 median: 16.0 sd: 1.0\n",
      "Beer: Claymore Lager\n",
      "mean: 9.0 median: 9.0 sd: 0.0\n",
      "Beer: Ritter Schwarz\n",
      "mean: 14.555555555555555 median: 15.0 sd: 2.408831487630978\n",
      "Beer: Three Boys Porter\n",
      "mean: 13.36 median: 13.0 sd: 1.8736061485808588\n",
      "Beer: Welde Remix\n",
      "mean: 5.833333333333333 median: 6.0 sd: 2.074983266331455\n",
      "Beer: Wye Valley Rapid Ale\n",
      "mean: 12.426229508196721 median: 13.0 sd: 1.928721791914188\n",
      "Beer: Cottage Planet Ale\n",
      "mean: 13.0 median: 13.0 sd: 0.0\n",
      "Beer: Earth We Heavy Yo\n",
      "mean: 15.133333333333333 median: 15.0 sd: 1.024152766382481\n",
      "Beer: Kenbach Beer\n",
      "mean: 6.0 median: 6.0 sd: 0.0\n",
      "Beer: Little Valley Yorkshire Hemp\n",
      "mean: 9.5 median: 9.5 sd: 3.5\n",
      "Beer: Dark Star Summer Meltdown\n",
      "mean: 13.0 median: 13.5 sd: 2.700762419587999\n",
      "Beer: North Country Abbey Holiday Ale\n",
      "mean: 9.0 median: 9.0 sd: 0.0\n",
      "Beer: Kronen Gold-Export\n",
      "mean: 12.166666666666666 median: 12.5 sd: 1.674979270186815\n",
      "Beer: Funfair Candy Floss\n",
      "mean: 15.0 median: 15.0 sd: 0.0\n",
      "Beer: Delafield Leisure Beer\n",
      "mean: 11.5 median: 11.5 sd: 2.5\n",
      "Beer: Coronado Seasons Best Winter Brew\n",
      "mean: 14.0 median: 14.0 sd: 1.591644851508443\n",
      "Beer: Papa Murphys Irish Amber Ale\n",
      "mean: 13.6 median: 14.0 sd: 1.4966629547095764\n",
      "Beer: Empire Royal Mead\n",
      "mean: 15.56 median: 16.0 sd: 1.820183140968696\n",
      "Beer: Elegancia Clasico\n",
      "mean: 16.0 median: 16.0 sd: 0.0\n",
      "Beer: Victory CBC Saison\n",
      "mean: 14.0 median: 14.0 sd: 1.0289915108550531\n",
      "Beer: Brau Brothers Extra Special Bitter\n",
      "mean: 13.473684210526315 median: 14.0 sd: 2.962367848309534\n",
      "Beer: La Jolla Brewhouse Pilsner\n",
      "mean: 14.0 median: 14.0 sd: 0.0\n",
      "Beer: Dempseys Petaluma Strong Ale\n",
      "mean: 13.8 median: 14.0 sd: 1.3266499161421599\n",
      "Beer: Wabash Pilsner\n",
      "mean: 10.0 median: 10.0 sd: 0.0\n",
      "Beer: Shepherd Neame Tapping The Admiral &#40;Bottle&#41;\n",
      "mean: 11.555555555555555 median: 12.0 sd: 1.0657403385139377\n",
      "Beer: Weasel Boy Feisty Fisher Amber Ale\n",
      "mean: 13.0 median: 13.0 sd: 0.816496580927726\n",
      "Beer: Bristol Beer Factory Ultimate Stout\n",
      "mean: 14.74074074074074 median: 15.0 sd: 1.4035033571478825\n",
      "Beer: The Civil Life Black Ale\n",
      "mean: 15.0 median: 15.0 sd: 0.816496580927726\n",
      "Beer: Il Vicino Sweet Sanderine Porter\n",
      "mean: 14.555555555555555 median: 14.0 sd: 0.9558139185602919\n",
      "Beer: Silverado Scottish Ale with Heather Tips\n",
      "mean: 10.0 median: 10.0 sd: 0.0\n",
      "Beer: Wormtown Beer Goggles Barleywine\n",
      "mean: 15.0 median: 15.0 sd: 0.0\n",
      "Beer: Saint-Bock 666\n",
      "mean: 13.7 median: 13.0 sd: 1.3453624047073711\n",
      "Beer: Barhop Judge Porter\n",
      "mean: 13.333333333333334 median: 14.0 sd: 1.3333333333333333\n",
      "Beer: Mallinsons Lynx\n",
      "mean: 13.0 median: 13.0 sd: 0.0\n",
      "Beer: 5 Seasons North AK-47 Mild Ale\n",
      "mean: 13.6 median: 13.0 sd: 1.2\n",
      "Beer: Goose Island Extremely Naughty Goose\n",
      "mean: 15.066666666666666 median: 15.0 sd: 1.4360439485692011\n",
      "Beer: Wedge Derailed iHemp Ale\n",
      "mean: 14.333333333333334 median: 14.5 sd: 1.9720265943665385\n",
      "Beer: Casco Bay Carrabassett IPA\n",
      "mean: 11.88888888888889 median: 11.0 sd: 2.5579698740491863\n",
      "Beer: Michelbacher Schwarzer Adler Dunkles Export\n",
      "mean: 12.0 median: 11.5 sd: 1.224744871391589\n",
      "Beer: North By Northwest Guldenbiere &#40;2005, 2007 and later&#41;\n",
      "mean: 15.074074074074074 median: 15.0 sd: 1.8242385712629259\n",
      "Beer: Shenandoah Blueberry Blonde\n",
      "mean: 10.5 median: 10.5 sd: 2.5\n",
      "Beer: Durham St Cuthbert\n",
      "mean: 13.909090909090908 median: 14.0 sd: 1.888780853605748\n",
      "Beer: Pittsburgh Gold Crown Premium Beer\n",
      "mean: 1.0 median: 1.0 sd: 0.0\n",
      "Beer: Sierra Madre Brewing Regio Light\n",
      "mean: 12.75 median: 11.5 sd: 4.437059837324712\n",
      "Beer: Blue Mountain Blue Reserve 2010\n",
      "mean: 14.6 median: 15.0 sd: 1.8547236990991407\n",
      "Beer: Big Dogs Red Hydrant Ale\n",
      "mean: 11.777777777777779 median: 12.0 sd: 1.6850834320114556\n",
      "Beer: Turtle Mountain Heather Scotch\n",
      "mean: 15.5 median: 15.5 sd: 0.5\n",
      "Beer: Saxer JackFrost Winter Doppelbock\n",
      "mean: 13.044117647058824 median: 13.0 sd: 2.3975098817769225\n",
      "Beer: North Peak Berserker\n",
      "mean: 17.0 median: 17.0 sd: 0.0\n",
      "Beer: Old Testy Stout\n",
      "mean: 13.2 median: 15.0 sd: 3.655133376499413\n",
      "Beer: Sweetwater Tavern Black IPA\n",
      "mean: 13.0 median: 13.0 sd: 0.0\n",
      "Beer: Amalgamated Imperial Oktoberfest &#40;Marzen&#41;\n",
      "mean: 15.0 median: 15.0 sd: 0.0\n",
      "Beer: Bull & Bush Ice Cream Clone Stout\n",
      "mean: 15.6 median: 16.0 sd: 1.624807680927192\n",
      "Beer: Acorn Simcoe IPA\n",
      "mean: 14.0 median: 14.0 sd: 0.816496580927726\n",
      "Beer: Maine Mead Works HoneyMaker Dry Hopped Mead\n",
      "mean: 11.714285714285714 median: 11.0 sd: 3.6140316116210047\n",
      "Beer: Great Waters Capitol ESB\n",
      "mean: 14.5 median: 14.5 sd: 0.5\n",
      "Beer: Brutopia Honey Brown\n",
      "mean: 10.75 median: 11.0 sd: 2.4585855399279595\n",
      "Beer: Ithaca Double IPA\n",
      "mean: 14.492537313432836 median: 15.0 sd: 1.7005103213698292\n",
      "Beer: Pocono Lager\n",
      "mean: 10.204545454545455 median: 10.0 sd: 3.0119424829603165\n",
      "Beer: Hartwall Karjala Terva &#40;6.3% version&#41;\n",
      "mean: 10.363636363636363 median: 10.0 sd: 2.6148547884611664\n",
      "Beer: Hartlands Medium Sweet Perry\n",
      "mean: 14.2 median: 15.0 sd: 1.1661903789690602\n",
      "Beer: Sarasota Brewing Coriander Wheat\n",
      "mean: 12.0 median: 12.0 sd: 1.0\n",
      "Beer: New Old Lompoc Crystal Missile Saison\n",
      "mean: 11.0 median: 11.0 sd: 0.0\n",
      "Beer: Samuel Adams Oatmeal Stout\n",
      "mean: 12.727272727272727 median: 14.0 sd: 3.3053925386723346\n",
      "Beer: Arcadia Starboard Stout\n",
      "mean: 12.868312757201647 median: 13.0 sd: 2.125473569337544\n",
      "Beer: Oggis HoliDazed Ale\n",
      "mean: 11.0 median: 11.0 sd: 1.0\n",
      "Beer: Big Dogs Mango Madness\n",
      "mean: 4.0 median: 4.0 sd: 0.0\n",
      "Beer: Bushwakker Northern Lights Lager\n",
      "mean: 11.8 median: 12.0 sd: 2.7129319932501073\n",
      "Beer: Smuttynose Oak-aged Terminator G-Bock\n",
      "mean: 14.857142857142858 median: 14.0 sd: 1.8070158058105024\n",
      "Beer: The Lucky Monk Tritica Wheat\n",
      "mean: 14.0 median: 13.5 sd: 1.8708286933869707\n",
      "Beer: Buntingford Honeyway\n",
      "mean: 13.0 median: 13.0 sd: 0.0\n",
      "Beer: Moab Brewery Desert Select Scotch Ale\n",
      "mean: 14.333333333333334 median: 15.0 sd: 1.699673171197595\n",
      "Beer: Brewers Art 10th Anniversary Ale\n",
      "mean: 15.285714285714286 median: 15.0 sd: 0.45175395145262565\n",
      "Beer: Clarks Code Red\n",
      "mean: 11.0 median: 11.0 sd: 1.0\n",
      "Beer: Lambrate Beccamort\n",
      "mean: 12.962962962962964 median: 13.0 sd: 1.5748364167014295\n",
      "Beer: Camerons Pomegranate Cream\n",
      "mean: 14.11111111111111 median: 15.0 sd: 1.3698697784375502\n",
      "Beer: Ryburn Best Mild\n",
      "mean: 13.4 median: 13.0 sd: 1.8547236990991407\n",
      "Beer: Bergadler Premium Pils 3.5\n",
      "mean: 11.0 median: 11.0 sd: 0.816496580927726\n",
      "Beer: Bullfrog eSTEAMed Beer\n",
      "mean: 13.2 median: 13.0 sd: 1.9390719429665317\n",
      "Beer: Lake Placid Pulpit Rock Dopplebock\n",
      "mean: 15.0 median: 15.0 sd: 0.0\n",
      "Beer: Sly Fox Slacker Eisbock\n",
      "mean: 14.166666666666666 median: 14.5 sd: 0.8975274678557508\n",
      "Beer: Flying Bison Bird of Prey IPA\n",
      "mean: 12.692307692307692 median: 13.0 sd: 1.3234346564680965\n",
      "Beer: Revolution El Bastardo\n",
      "mean: 13.5 median: 14.0 sd: 2.29128784747792\n",
      "Beer: Kaiser Wilhelm II Premium Pils\n",
      "mean: 11.0 median: 11.0 sd: 0.0\n",
      "Beer: Flying Fish Love Fish\n",
      "mean: 14.518518518518519 median: 15.0 sd: 1.4998856838012287\n",
      "Beer: 21st Amendment Belgian Strong Ale\n",
      "mean: 15.0 median: 15.0 sd: 0.0\n",
      "Beer: Cascade Amber Wheat\n",
      "mean: 13.5 median: 13.5 sd: 0.5\n",
      "\n",
      "\n",
      "Brewer: 0\n",
      "mean: 12.836223506743737 median: 13.0 sd: 2.5432971325766625\n",
      "Brewer: 1\n",
      "mean: 13.251677852348994 median: 14.0 sd: 2.7974845850519783\n",
      "Brewer: 2\n",
      "mean: 14.822445170321979 median: 15.0 sd: 2.243541088466132\n",
      "Brewer: 3\n",
      "mean: 13.8 median: 14.0 sd: 2.6381811916545836\n",
      "Brewer: 4\n",
      "mean: 11.64 median: 12.0 sd: 2.4799999999999995\n",
      "Brewer: 5\n",
      "mean: 10.0 median: 10.0 sd: 0.0\n",
      "Brewer: 6\n",
      "mean: 9.86111111111111 median: 11.0 sd: 4.619720877678035\n",
      "Brewer: 7\n",
      "mean: 9.206106870229007 median: 9.0 sd: 3.174607163897181\n",
      "Brewer: 8\n",
      "mean: 12.442857142857143 median: 13.0 sd: 2.168842444950856\n",
      "Brewer: 9\n",
      "mean: 9.533333333333333 median: 10.0 sd: 3.630733014450694\n",
      "Brewer: 10\n",
      "mean: 14.141904761904762 median: 14.0 sd: 2.2235084939517855\n",
      "Brewer: 11\n",
      "mean: 13.867924528301886 median: 14.0 sd: 1.6372749547106897\n",
      "Brewer: 12\n",
      "mean: 14.57345971563981 median: 15.0 sd: 2.7332237455074773\n",
      "Brewer: 13\n",
      "mean: 11.0 median: 11.0 sd: 2.0\n",
      "Brewer: 14\n",
      "mean: 13.333333333333334 median: 13.0 sd: 0.4714045207910317\n",
      "Brewer: 15\n",
      "mean: 6.123473282442748 median: 5.0 sd: 4.4324147087168555\n",
      "Brewer: 16\n",
      "mean: 11.9 median: 13.0 sd: 3.3301651610693423\n",
      "Brewer: 17\n",
      "mean: 12.831683168316832 median: 13.0 sd: 3.0222583744272926\n",
      "Brewer: 18\n",
      "mean: 14.2109337860781 median: 14.0 sd: 2.455233690037572\n",
      "Brewer: 19\n",
      "mean: 13.358490566037736 median: 13.0 sd: 1.7385131320436895\n",
      "Brewer: 20\n",
      "mean: 13.95 median: 14.0 sd: 2.423324163210527\n",
      "Brewer: 21\n",
      "mean: 12.414429278536073 median: 13.0 sd: 2.57923577104781\n",
      "Brewer: 22\n",
      "mean: 14.584699453551913 median: 15.0 sd: 2.2917097265342896\n",
      "Brewer: 23\n",
      "mean: 5.0 median: 5.0 sd: 0.0\n",
      "Brewer: 24\n",
      "mean: 12.75 median: 13.0 sd: 2.165063509461097\n",
      "Brewer: 25\n",
      "mean: 9.135135135135135 median: 9.0 sd: 4.094572295006621\n",
      "Brewer: 26\n",
      "mean: 12.615384615384615 median: 13.0 sd: 1.4163040491939975\n",
      "Brewer: 27\n",
      "mean: 11.550617283950617 median: 12.0 sd: 2.1649351175970537\n",
      "Brewer: 28\n",
      "mean: 13.2 median: 13.0 sd: 0.7483314773547882\n",
      "Brewer: 29\n",
      "mean: 11.0 median: 11.0 sd: 0.0\n",
      "Brewer: 30\n",
      "mean: 9.333333333333334 median: 9.0 sd: 3.822875761121112\n",
      "Brewer: 31\n",
      "mean: 11.4 median: 12.0 sd: 2.5508168626278653\n",
      "Brewer: 32\n",
      "mean: 11.958041958041958 median: 12.0 sd: 2.31103804931299\n",
      "Brewer: 33\n",
      "mean: 14.018181818181818 median: 14.0 sd: 2.3470748455425348\n",
      "Brewer: 34\n",
      "mean: 11.666666666666666 median: 12.0 sd: 1.6996731711975948\n",
      "Brewer: 35\n",
      "mean: 12.909090909090908 median: 14.0 sd: 1.928473039599675\n",
      "Brewer: 36\n",
      "mean: 12.565014031805426 median: 13.0 sd: 2.5881523842441694\n",
      "Brewer: 37\n",
      "mean: 14.78 median: 15.0 sd: 1.446236495183274\n",
      "Brewer: 38\n",
      "mean: 12.901639344262295 median: 13.0 sd: 2.0098521112936893\n",
      "Brewer: 39\n",
      "mean: 14.913769123783032 median: 15.0 sd: 2.2997410768192283\n",
      "Brewer: 40\n",
      "mean: 14.853696456334102 median: 15.0 sd: 2.4378154506466116\n",
      "Brewer: 41\n",
      "mean: 12.166666666666666 median: 13.0 sd: 2.3746344747958346\n",
      "Brewer: 42\n",
      "mean: 13.529411764705882 median: 14.0 sd: 2.0802803466470343\n",
      "Brewer: 43\n",
      "mean: 14.0 median: 14.0 sd: 0.816496580927726\n",
      "Brewer: 44\n",
      "mean: 12.371308016877638 median: 13.0 sd: 2.6268051012868656\n",
      "Brewer: 45\n",
      "mean: 12.04109589041096 median: 13.0 sd: 2.951379320743882\n",
      "Brewer: 46\n",
      "mean: 11.9 median: 12.5 sd: 1.8411952639521967\n",
      "Brewer: 47\n",
      "mean: 11.1875 median: 12.0 sd: 2.9201615965559165\n",
      "Brewer: 48\n",
      "mean: 12.707207207207206 median: 13.0 sd: 2.268039265581248\n",
      "Brewer: 49\n",
      "mean: 13.459694989106755 median: 13.0 sd: 2.34032768560976\n",
      "Brewer: 50\n",
      "mean: 17.333333333333332 median: 17.0 sd: 1.247219128924647\n",
      "Brewer: 51\n",
      "mean: 11.5 median: 11.5 sd: 3.5\n",
      "Brewer: 52\n",
      "mean: 14.294621026894866 median: 15.0 sd: 2.2118806600771648\n",
      "Brewer: 53\n",
      "mean: 12.545454545454545 median: 13.0 sd: 1.6713433009863852\n",
      "Brewer: 54\n",
      "mean: 12.5625 median: 13.0 sd: 0.7043392293490403\n",
      "Brewer: 55\n",
      "mean: 12.952380952380953 median: 13.0 sd: 1.8381199110113127\n",
      "Brewer: 56\n",
      "mean: 12.976027397260275 median: 13.0 sd: 2.562126813307368\n",
      "Brewer: 57\n",
      "mean: 13.0 median: 13.0 sd: 1.632993161855452\n",
      "Brewer: 58\n",
      "mean: 12.76923076923077 median: 14.0 sd: 2.832608098387995\n",
      "Brewer: 59\n",
      "mean: 12.211678832116789 median: 12.0 sd: 2.27146904757196\n",
      "Brewer: 60\n",
      "mean: 11.88888888888889 median: 12.0 sd: 2.469567863432541\n",
      "Brewer: 61\n",
      "mean: 11.112903225806452 median: 11.5 sd: 2.103030368912974\n",
      "Brewer: 62\n",
      "mean: 11.76923076923077 median: 11.0 sd: 1.7166087388016462\n",
      "Brewer: 63\n",
      "mean: 13.256410256410257 median: 13.0 sd: 1.3722141702830413\n",
      "Brewer: 64\n",
      "mean: 11.325892857142858 median: 12.0 sd: 3.4841540666206163\n",
      "Brewer: 65\n",
      "mean: 20.0 median: 20.0 sd: 0.0\n",
      "Brewer: 66\n",
      "mean: 13.666666666666666 median: 14.0 sd: 1.247219128924647\n",
      "Brewer: 67\n",
      "mean: 13.024896265560166 median: 14.0 sd: 3.2907834469368167\n",
      "Brewer: 68\n",
      "mean: 13.5 median: 13.5 sd: 0.5\n",
      "Brewer: 69\n",
      "mean: 12.56 median: 13.0 sd: 2.786826151736057\n",
      "Brewer: 70\n",
      "mean: 15.386691484411354 median: 16.0 sd: 1.9307050162261605\n",
      "Brewer: 71\n",
      "mean: 11.0 median: 11.0 sd: 0.0\n",
      "Brewer: 72\n",
      "mean: 13.015094339622642 median: 13.0 sd: 2.293501584782954\n",
      "Brewer: 73\n",
      "mean: 12.6 median: 11.0 sd: 2.4166091947189146\n",
      "Brewer: 74\n",
      "mean: 11.10344827586207 median: 12.0 sd: 2.3758095184619217\n",
      "Brewer: 75\n",
      "mean: 12.924679487179487 median: 13.0 sd: 2.3789474401324124\n",
      "Brewer: 76\n",
      "mean: 12.5 median: 13.0 sd: 2.909676307807488\n",
      "Brewer: 77\n",
      "mean: 6.3253588516746415 median: 6.0 sd: 3.341686533827527\n",
      "Brewer: 78\n",
      "mean: 15.529032258064516 median: 16.0 sd: 2.147195252084058\n",
      "Brewer: 79\n",
      "mean: 10.0 median: 10.0 sd: 0.0\n",
      "Brewer: 80\n",
      "mean: 13.698863636363637 median: 14.0 sd: 2.341619210473706\n",
      "Brewer: 81\n",
      "mean: 13.875 median: 13.0 sd: 2.1469455046647083\n",
      "Brewer: 82\n",
      "mean: 12.8 median: 12.5 sd: 0.9797958971132712\n",
      "Brewer: 83\n",
      "mean: 14.114543114543114 median: 14.0 sd: 2.180056338876711\n",
      "Brewer: 84\n",
      "mean: 12.19047619047619 median: 14.0 sd: 3.7999880653828573\n",
      "Brewer: 85\n",
      "mean: 10.901960784313726 median: 11.0 sd: 1.6716189400742834\n",
      "Brewer: 86\n",
      "mean: 11.333333333333334 median: 12.0 sd: 3.2180049029725786\n",
      "Brewer: 87\n",
      "mean: 8.431034482758621 median: 9.0 sd: 2.7044794831303505\n",
      "Brewer: 88\n",
      "mean: 13.872865275142315 median: 14.0 sd: 2.3093251983625622\n",
      "Brewer: 89\n",
      "mean: 14.966666666666667 median: 15.0 sd: 1.32874209519965\n",
      "Brewer: 90\n",
      "mean: 10.75 median: 11.5 sd: 1.6393596310755\n",
      "Brewer: 91\n",
      "mean: 13.008849557522124 median: 13.0 sd: 2.462086226757002\n",
      "Brewer: 92\n",
      "mean: 12.485714285714286 median: 13.0 sd: 1.8878775470493474\n",
      "Brewer: 93\n",
      "mean: 14.0 median: 14.5 sd: 1.5491933384829668\n",
      "Brewer: 94\n",
      "mean: 10.966666666666667 median: 11.0 sd: 2.726210230745645\n",
      "Brewer: 95\n",
      "mean: 13.466908861159375 median: 14.0 sd: 2.4414100283035616\n",
      "Brewer: 96\n",
      "mean: 15.0 median: 15.0 sd: 2.0\n",
      "Brewer: 97\n",
      "mean: 11.571428571428571 median: 13.0 sd: 4.135461378894322\n",
      "Brewer: 98\n",
      "mean: 13.041666666666666 median: 13.0 sd: 1.135751097536584\n",
      "Brewer: 99\n",
      "mean: 7.5 median: 7.0 sd: 1.5\n"
     ]
    }
   ],
   "source": [
    "#For the sake of not printing too much stuff, I only print the first 100 items.\n",
    "for k,v in list(beer_statistics.items())[:100]:\n",
    "    print(\"Beer: \" + str(k) +\"\\n\" \n",
    "          + \"mean: \" + str(v['mean']) \n",
    "          + \" median: \" + str(v['median']) \n",
    "          + \" sd: \" + str(v['sd']))\n",
    "print(\"\\n\")\n",
    "for k,v in list(brewer_statistics.items())[:100]:\n",
    "    print(\"Brewer: \" + str(k) +\"\\n\" \n",
    "          + \"mean: \" + str(v['mean']) \n",
    "          + \" median: \" + str(v['median']) \n",
    "          + \" sd: \" + str(v['sd']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like people have different tastes, but there are definitely beers and brewer that are generally more liked. This is apparrent because the standard deviations are not too high, but the beers and brewers with a significant amount of reviews do have a decent standard deviation. which shows that there is definitely some differentiation in taste. There is also an extreme range of means, which shows that there is some form of objective ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/project/cmsc25025/beer_review/vocab_30.json', 'r') as f:\n",
    "         vocab = json.load(f)\n",
    "vocab_set = set(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = [1 if b['overall'] >=14 else 0 for b in brv]\n",
    "\n",
    "demo_brv = brv[:10000]\n",
    "demo_ratings = ratings[:10000]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Generating features.\n",
    "You need to represent text reviews in terms of a vector of features (covariates). One simple but effective representation is to use membership in a fixed vocab- ulary. Suppose the vocabulary contains p words. For a given review, you normalize the text, and separate it into space-delimited tokens. For each of the tokens, if it is in the dictionary you have a one for the corresponding word in the feature vector, and you ignore it otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeCSRandLabels(words, ratings):\n",
    "    vocab_words = [list(vocab_set & set(re.sub(\"[^\\w]\", \" \",  br['review'].lower()).split())) for br in words]\n",
    "    vocab_words_ratings = [(x, ratings[i]) for i,x in enumerate(vocab_words) if x != []]\n",
    "    vocab_words = [x for x,i in vocab_words_ratings]\n",
    "    csr_ratings = [i for x,i in vocab_words_ratings]\n",
    "    indptr = [0]\n",
    "    indices = []\n",
    "    data = []\n",
    "    vocabulary = {}\n",
    "    for v in vocab:\n",
    "        index = vocabulary.setdefault(v, len(vocabulary))\n",
    "    for d in vocab_words:\n",
    "        for term in d:\n",
    "            index = vocabulary.setdefault(term, len(vocabulary))\n",
    "            indices.append(index)\n",
    "            data.append(1)\n",
    "        indptr.append(len(indices))\n",
    "    return csr_matrix((data, indices, indptr)), csr_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "csr_vocab, csr_labels = makeCSRandLabels(demo_brv, demo_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Logistic regression using Newton’s method\n",
    "Logistic regression using Newton’s method. Train an l2-regularized logistic regression\n",
    "classifier using the sklearn.linear model.LogisticRegression class. To select the regularization parameter C = 1/λ, you should try different values on the validation\n",
    "set. Pick the best. How long does it take to train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDualDataRange(data, ratings,l,r):\n",
    "    return csr_matrix(data[int(l*len(data)):int(r*len(data))]), ratings[int(l*len(ratings)):int(r*len(ratings))]\n",
    "\n",
    "train_csr_words, train_ratings = getDualDataRange(csr_vocab.toarray(), csr_labels, 0, 0.7)\n",
    "valid_csr_words, valid_ratings = getDualDataRange(csr_vocab.toarray(), csr_labels, 0.7, 0.85)\n",
    "test_csr_words, test_ratings = getDualDataRange(csr_vocab.toarray(), csr_labels, 0.85, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing for best lambda\n",
    "\n",
    "ltrain_csr_words, ltrain_ratings = getDualDataRange(csr_vocab.toarray(), csr_labels, 0, 0.07)\n",
    "lvalid_csr_words, lvalid_ratings = getDualDataRange(csr_vocab.toarray(), csr_labels, 0.07, 0.085)\n",
    "\n",
    "ls = [5,10,20,30,40,50,75,100,200,300,400,500]\n",
    "errors = []\n",
    "for l in ls:\n",
    "    lg=LogisticRegression(fit_intercept=True, C=l, penalty='l2',\n",
    "                multi_class='multinomial',solver='newton-cg')\n",
    "    model = lg.fit(ltrain_csr_words, ltrain_ratings)\n",
    "    predicted_valid_ratings = lg.predict(lvalid_csr_words)\n",
    "    error = np.mean(lvalid_ratings != predicted_valid_ratings)\n",
    "    errors.append(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error rate for 1/lambda = 5 is 0.36\n",
      "The error rate for 1/lambda = 10 is 0.36\n",
      "The error rate for 1/lambda = 20 is 0.35333333333333333\n",
      "The error rate for 1/lambda = 30 is 0.36\n",
      "The error rate for 1/lambda = 40 is 0.36\n",
      "The error rate for 1/lambda = 50 is 0.36\n",
      "The error rate for 1/lambda = 75 is 0.36666666666666664\n",
      "The error rate for 1/lambda = 100 is 0.36666666666666664\n",
      "The error rate for 1/lambda = 200 is 0.36\n",
      "The error rate for 1/lambda = 300 is 0.36666666666666664\n",
      "The error rate for 1/lambda = 400 is 0.36666666666666664\n",
      "The error rate for 1/lambda = 500 is 0.36666666666666664\n",
      "The minimum 1/lambda value is: 20\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(ls)):\n",
    "    print(\"The error rate for 1/lambda = \" + str(ls[i]) + \" is \" + str(errors[i]))\n",
    "error_pairs = [(ls[i], errors[i]) for i in range(len(ls))]\n",
    "min_pair = min(error_pairs, key = lambda x: x[1])\n",
    "print(\"The minimum 1/lambda value is: \" + str(min_pair[0]))\n",
    "l = min_pair[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning the model took 11.313294887542725 seconds.\n"
     ]
    }
   ],
   "source": [
    "#Fitting the Regression\n",
    "start_time = time.time()\n",
    "lg=LogisticRegression(fit_intercept=True, C=l, penalty='l2',\n",
    "                multi_class='multinomial',solver='newton-cg')\n",
    "model = lg.fit(train_csr_words, train_ratings)\n",
    "end_time = time.time()\n",
    "print(\"Traning the model took %s seconds.\" % (end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error rate is: 0.19786096256684493\n"
     ]
    }
   ],
   "source": [
    "# Testing the Training\n",
    "predicted_test_ratings = lg.predict(test_csr_words)\n",
    "error = np.mean(test_ratings != predicted_test_ratings)\n",
    "print(\"The error rate is:\", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same thing using the LinearSVC class in sklearn.svm. Use loss=’hinge’. Compare the results of the logistic loss to the hinge loss. Is there a difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltrain_csr_words, ltrain_ratings = getDualDataRange(csr_vocab.toarray(), csr_labels, 0, 0.07)\n",
    "lvalid_csr_words, lvalid_ratings = getDualDataRange(csr_vocab.toarray(), csr_labels, 0.07, 0.085)\n",
    "\n",
    "ls = [5,10,20,30,40,50,75,100,200,300,400,500]\n",
    "errors = []\n",
    "for l in ls:\n",
    "    hinge=LinearSVC(loss='hinge', penalty='l2',dual=True, tol=.001, C = l, max_iter = 100000)\n",
    "    model = hinge.fit(ltrain_csr_words, ltrain_ratings)\n",
    "    predicted_valid_ratings = hinge.predict(lvalid_csr_words)\n",
    "    error = np.mean(lvalid_ratings != predicted_valid_ratings)\n",
    "    errors.append(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_pairs = [(ls[i], errors[i]) for i in range(len(ls))]\n",
    "min_pair = min(error_pairs, key = lambda x: x[1])\n",
    "lhinge = min_pair[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning the model took 8.50538682937622 seconds.\n"
     ]
    }
   ],
   "source": [
    "#Fitting the Regression\n",
    "\n",
    "start_time = time.time()\n",
    "hinge=LinearSVC(loss='hinge', penalty='l2',dual=True, tol=.001, C = l, max_iter = 100000)\n",
    "model = hinge.fit(train_csr_words, train_ratings)\n",
    "end_time = time.time()\n",
    "print(\"Traning the model took %s seconds.\" % (end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error rate is: 0.2520053475935829\n"
     ]
    }
   ],
   "source": [
    "# Testing the Training\n",
    "predicted_test_ratings = hinge.predict(test_csr_words)\n",
    "error = np.mean(test_ratings != predicted_test_ratings)\n",
    "print(\"The error rate is:\", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hinge model was extremely faster, but does get a slightly higher error rate. This is important to realize as using hinge is probably better when in an instance where you are willing to sacrifice accuracy for a faster runtime. For instance, if your dataset is extremely large and you are only testing whether the model is good and thus can sacrifice some accuracay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Stochastic gradient descent\n",
    " Your next job is to train an l2-regularized logistic regression\n",
    "classifier using stochastic gradient descent. Recall the SGD framework that was covered in\n",
    "class using minibatches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i. Initialize the model with θ = 0 (uniform)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. Randomly split the training data into mini-batches. Make one pass of the data, processing one mini-batch in every iteration. This is called one training epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getYhat(x, theta):\n",
    "    return 1/(1+exp(-theta.dot(x)))\n",
    "\n",
    "def getNewThetas(x, y, yhat, thetas, alpha, lamb):\n",
    "    return thetas + alpha*((y - yhat) * yhat *(1 - yhat) * x - 2*lamb*thetas)\n",
    "\n",
    "def getBatch(b, x, y):\n",
    "    indices = random.sample(range(len(y)), b)\n",
    "    xb = [x.getrow(i).toarray()[0] for i in indices]\n",
    "    yb = [y[i] for i in indices]\n",
    "    return xb,yb\n",
    "\n",
    "def SGDstep(x,y, theta, alpha, lamb, b):\n",
    "    xb, yb = getBatch(b, x, y)\n",
    "    for i in range(b):\n",
    "        yhat = getYhat(xb[i],theta)\n",
    "        theta = getNewThetas(xb[i], yb[i], yhat, theta, alpha, lamb)\n",
    "    return theta\n",
    "\n",
    "def predictSGD(X,theta):\n",
    "    yhats = []\n",
    "    for i in range(X.shape[0]):\n",
    "        x = X.getrow(i).toarray()[0]\n",
    "        yhats.append(getYhat(x, theta))\n",
    "    return yhats  \n",
    "    \n",
    "\n",
    "def runSGDsteps(x, y, theta, alpha, lamb, b, n):\n",
    "    thetas = []\n",
    "    for i in range(n):\n",
    "        theta = SGDstep(x, y, theta, alpha, lamb, b)\n",
    "        thetas.append(theta)\n",
    "    \n",
    "    return theta, thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error rate is: 0.15641711229946523\n"
     ]
    }
   ],
   "source": [
    "theta = SGDstep(train_csr_words, train_ratings, np.zeros(len(vocab)), 0.001, 1/l, 10)\n",
    "yhats = predictSGD(test_csr_words, theta)\n",
    "predicted_test_ratings = [1 if yhat >= 0.5 else 0 for yhat in yhats]\n",
    "wrong = 0\n",
    "for i in range(len(test_ratings)):\n",
    "    if test_ratings[i] != predicted_test_ratings[i]:\n",
    "        wrong += 1\n",
    "error = wrong/len(test_ratings)\n",
    "print(\"The error rate is:\", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii. Repeat the last step a few times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning the model took 2.682340621948242 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "theta, thetas = runSGDsteps(train_csr_words, train_ratings, np.zeros(len(vocab)), 0.001, 1/l, 100, 10)\n",
    "end_time = time.time()\n",
    "print(\"Traning the model took %s seconds.\" % (end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(x, y, theta):\n",
    "    scores = np.dot(x, theta)\n",
    "    ll = np.sum( y*scores - np.log(1 + np.exp(y)) )\n",
    "    return ll\n",
    "\n",
    "errors = []\n",
    "ll = []\n",
    "for theta in thetas:\n",
    "    yhats = predictSGD(test_csr_words, theta)\n",
    "    predicted_test_ratings = [1 if yhat >= 0.5 else 0 for yhat in yhats]\n",
    "    wrong = 0\n",
    "    for i in range(len(test_ratings)):\n",
    "        if test_ratings[i] != predicted_test_ratings[i]:\n",
    "            wrong += 1\n",
    "    errors.append(wrong/len(test_ratings))\n",
    "    #Note that computing the log likelihood kills the kernal and uses a lot of memory, so I commented it out. If you want to try to compute it, uncomment this.\n",
    "    # ll.append(log_likelihood(test_csr_words,test_ratings,theta))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(errors)\n",
    "plt.ylabel('errors')\n",
    "plt.xlabel('iterations')\n",
    "plt.show()\n",
    "if (len(ll)>0):\n",
    "    plt.plot(ll)\n",
    "    plt.ylabel('log-likelihood')\n",
    "    plt.xlabel('iterations')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best error rate is: 0.11229946524064172\n"
     ]
    }
   ],
   "source": [
    "error = min(errors)\n",
    "print(\"The best error rate is:\", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the error rate generally shrinks at first, but once it reaches a minimum, it begins to increase. This the behavior that we expect with SGD. As it is stochastic, we cannot expect the same behavior for every run and in some cases, the error rate may even increase.It appears that the best results happen around 3-5 iteraitons. Overall, the change in error rate is extremely small after the first iteration and thus if we run too many or too little iterations, it is not too big of a deal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error rate for SGD was significantly better than the error rate for the logistic and hinge regression. It runs slower than the hinge regression, but still runs fairly fast. This is definitely the best prediction function as it runs fast enough and has the best error rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Scores versus text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to text reviews, the users also scored appearance, aroma, palate, style, taste of\n",
    "a beer. In this problem, you will check whether those scores could reflect people’s opinion\n",
    "better than text.\n",
    "Train another logistic regression model using those features. You should use the same SGD\n",
    "algorithm as before. Compare the model using score features with that using review text.\n",
    "Again, use the validation set to tune the regularization parameters, and retrain the model on\n",
    "the union of training and validation set. Finally, compute the prediction error on the testing\n",
    "set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [[b[\"appearance\"], b[\"aroma\"], b[\"palate\"], b[\"style\"], b[\"taste\"]] for b in brv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_scores = scores[:10000]\n",
    "demo_ratings = ratings[:10000]\n",
    "\n",
    "def getDataRange(data, l, r):\n",
    "    return data[int(l*len(data)):int(r*len(data))]\n",
    "    \n",
    "\n",
    "train_scores = getDataRange(demo_scores, 0, 0.7)\n",
    "valid_scores = getDataRange(demo_scores, 0.7, 0.85)\n",
    "test_scores = getDataRange(demo_scores, 0.85, 1)\n",
    "\n",
    "train_ratings = getDataRange(demo_ratings, 0, 0.7)\n",
    "valid_ratings = getDataRange(demo_ratings, 0.7, 0.85)\n",
    "test_ratings = getDataRange(demo_ratings, 0.85, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing for best lambda\n",
    "\n",
    "ltrain_scores = getDataRange(demo_scores, 0, 0.7)\n",
    "lvalid_scores = getDataRange(demo_scores, 0.7, 0.85)\n",
    "ltrain_ratings = getDataRange(demo_ratings, 0, 0.7)\n",
    "lvalid_ratings = getDataRange(demo_ratings, 0.7, 0.85)\n",
    "\n",
    "ls = [5, 10, 20, 30, 40, 50, 75, 100, 200, 300, 400,500, 1000, 2000, 5000, 10000]\n",
    "errors = []\n",
    "for l in ls:\n",
    "    lg=LogisticRegression(fit_intercept=True, C=l, penalty='l2',\n",
    "                multi_class='multinomial',solver='newton-cg')\n",
    "    model = lg.fit(ltrain_scores, ltrain_ratings)\n",
    "    predicted_valid_ratings = lg.predict(lvalid_scores)\n",
    "    error = np.mean(lvalid_ratings != predicted_valid_ratings)\n",
    "    errors.append(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_pairs = [(ls[i], errors[i]) for i in range(len(ls))]\n",
    "min_pair = min(error_pairs, key = lambda x: x[1])\n",
    "l = min_pair[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning the model took 0.2636234760284424 seconds.\n"
     ]
    }
   ],
   "source": [
    "#Fitting the Regression\n",
    "start_time = time.time()\n",
    "lg=LogisticRegression(fit_intercept=True, C=l, penalty='l2',\n",
    "                multi_class='multinomial',solver='newton-cg')\n",
    "model = lg.fit(train_scores, train_ratings)\n",
    "end_time = time.time()\n",
    "print(\"Traning the model took %s seconds.\" % (end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error rate is: 0.09\n"
     ]
    }
   ],
   "source": [
    "# Testing the Training\n",
    "predicted_test_ratings = lg.predict(test_scores)\n",
    "error = np.mean(test_ratings != predicted_test_ratings)\n",
    "print(\"The error rate is:\", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning the model took 0.008984565734863281 seconds.\n"
     ]
    }
   ],
   "source": [
    "#Running the SGD\n",
    "def getScoreBatch(b, x, y):\n",
    "    indices = random.sample(range(len(y)), b)\n",
    "    xb = [x[i] for i in indices]\n",
    "    yb = [y[i] for i in indices]\n",
    "    return np.array(xb),np.array(yb)\n",
    "\n",
    "def SGDScoreStep(x,y, theta, alpha, lamb, b):\n",
    "    xb, yb = getScoreBatch(b, x, y)\n",
    "    for i in range(b):\n",
    "        yhat = getYhat(xb[i],theta)\n",
    "        theta = getNewThetas(xb[i], yb[i], yhat, theta, alpha, lamb)\n",
    "    return theta\n",
    "\n",
    "def runSGDScoreSteps(x, y, theta, alpha, lamb, b, n):\n",
    "    for i in range(n):\n",
    "        theta = SGDScoreStep(x, y, theta, alpha, lamb, b)\n",
    "    return theta\n",
    "\n",
    "start_time = time.time()\n",
    "theta = runSGDScoreSteps(train_scores, train_ratings, np.zeros(len(test_scores[0])), 0.001, 1/l, 100, 5)\n",
    "end_time = time.time()\n",
    "print(\"Traning the model took %s seconds.\" % (end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictScoresSGD(X,theta):\n",
    "    yhats = []\n",
    "    for i in range(len(X)):\n",
    "        x = X[i]\n",
    "        yhats.append(getYhat(x, theta))\n",
    "    return yhats\n",
    "\n",
    "yhats = predictScoresSGD(test_scores, theta)\n",
    "\n",
    "predicted_test_ratings = [1 if yhat >= 0.5 else 0 for yhat in yhats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error rate is: 0.11133333333333334\n"
     ]
    }
   ],
   "source": [
    "wrong = 0\n",
    "for i in range(len(test_ratings)):\n",
    "    if test_ratings[i] != predicted_test_ratings[i]:\n",
    "        wrong += 1\n",
    "error = wrong/len(test_ratings)\n",
    "print(\"The error rate is:\", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which model predicts better? Is the representation you constructed for text more powerful,\n",
    "or are the scores? Why? Comment on your findings and discuss your thinking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scores model predicts way better than the test model in every case, but SGD. This makes sense as sentiment analysis is an extremely conplex field and thus our model does not do a fantastic job of performing it. In addition, there is a much more objective relationship between the scores and the ratings. The text in the review is informative, but it is far less deterministic of the actual rating. \n",
    "\n",
    "In the case of SGD, they interestingly get about the same error rate. This is a significant note as it shows that the power of the scores and text are about the same in determining the actual rating. I was really suprised to see this as I imagined that it would be better for the scores. However, with the scores, there are far more dimensions and thus it makes sense that SGD would perform well on the text."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
